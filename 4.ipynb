{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xRBVDa0gi31kxHYFTH0TYqSCciuBFInw","timestamp":1712605464118}],"gpuType":"T4","authorship_tag":"ABX9TyNE1vHXnytB2Pu7lowf4sdv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPesGFkHZ2SS","executionInfo":{"status":"ok","timestamp":1712527299215,"user_tz":-120,"elapsed":10358,"user":{"displayName":"Danilo Joncic","userId":"12467872683224926268"}},"outputId":"0aa9b5b5-c421-4cdb-f41f-0c798101af24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7874015748031497\n","Najčešće reči u pozitivnim tvitovima: [('http', 1661), ('fire', 177), ('bomb', 111), ('kill', 101), ('via', 87)]\n","Najčešće reči u negativnim tvitovima: [('http', 1492), ('like', 195), ('get', 145), ('new', 132), ('amp', 132)]\n","Top 5 reči sa najvećom LR vrednošću: [('kill', 8.416666666666666), ('train', 5.230769230769231), ('report', 4.8), ('evacu', 3.9444444444444446), ('famili', 3.619047619047619)]\n","Top 5 reči sa najmanjom LR vrednošću: [('feel', 0.22916666666666666), ('want', 0.2), ('love', 0.18309859154929578), ('obliter', 0.1694915254237288), ('scream', 0.15151515151515152)]\n"]}],"source":["!pip install nltk\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","#Veliko hvala freeCodeCamp, Youtube i naravno StackOverflow\n","\n","\n","import numpy as np\n","import pandas as pd\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from string import punctuation\n","\n","# Učitavanje podataka\n","df = pd.read_csv('disaster-tweets.csv').dropna()\n","\n","# Priprema podataka\n","stop_words = set(stopwords.words('english')) | set(punctuation)\n","stemmer = PorterStemmer()\n","\n","def preprocess(text):\n","    tokens = word_tokenize(text.lower())\n","    filtered = [stemmer.stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n","    return filtered\n","\n","df['processed'] = df['text'].apply(preprocess)\n","\n","# Kreiranje vokabulara\n","all_words = [word for tokens in df['processed'] for word in tokens]\n","word_freq = nltk.FreqDist(all_words)\n","common_words = word_freq.most_common(10000)\n","vocab = [word[0] for word in common_words]\n","\n","# Kreiranje BoW feature vektora\n","def create_features(tokens):\n","    features = np.zeros(len(vocab), dtype=np.float32)\n","    for token in tokens:\n","        if token in vocab:\n","            features[vocab.index(token)] += 1\n","    return features\n","\n","X = np.array([create_features(tokens) for tokens in df['processed']])\n","y = df['target'].values\n","\n","# Podela podataka na trening i test skupove \"ručno\"\n","def train_test_split_manual(X, y, test_size=0.2):\n","    indices = np.arange(X.shape[0])\n","    np.random.shuffle(indices)\n","    split_idx = int(X.shape[0] * (1-test_size))\n","    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n","    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n","\n","X_train, X_test, y_train, y_test = train_test_split_manual(X, y, test_size=0.2)\n","\n","# Implementacija Naive Bayes klasifikatora\n","class NaiveBayesClassifier:\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","        self.classes = np.unique(y)\n","        n_classes = len(self.classes)\n","\n","        # Inicijalizacija parametara\n","        self.priors = np.zeros(n_classes, dtype=np.float64)\n","        self.likelihoods = np.zeros((n_classes, n_features), dtype=np.float64)\n","\n","        for idx, c in enumerate(self.classes):\n","            X_c = X[y == c]\n","            self.priors[idx] = X_c.shape[0] / float(n_samples)\n","            self.likelihoods[idx, :] = (np.sum(X_c, axis=0) + 1) / (np.sum(X_c) + n_features)\n","\n","    def predict(self, X):\n","        y_pred = [self._predict(x) for x in X]\n","        return np.array(y_pred)\n","\n","    def _predict(self, x):\n","        posteriors = []\n","\n","        for idx, c in enumerate(self.classes):\n","            prior = np.log(self.priors[idx])\n","            likelihood = np.sum(np.log(self.likelihoods[idx]) * x)\n","            posterior = prior + likelihood\n","            posteriors.append(posterior)\n","\n","        return self.classes[np.argmax(posteriors)]\n","\n","# Treniranje i evaluacija modela\n","model = NaiveBayesClassifier()\n","model.fit(X_train, y_train)\n","predictions = model.predict(X_test)\n","\n","# Ručno izračunavanje tačnosti\n","def accuracy_score_manual(y_true, y_pred):\n","    correct = np.sum(y_true == y_pred)\n","    return correct / len(y_true)\n","\n","accuracy = accuracy_score_manual(y_test, predictions)\n","print(f'Accuracy: {accuracy}')\n","\n","# Analiza reči i LR metrike ostaje ista\n","positive_words = [word for tokens in df[df['target'] == 1]['processed'] for word in tokens]\n","negative_words = [word for tokens in df[df['target'] == 0]['processed'] for word in tokens]\n","positive_freq = nltk.FreqDist(positive_words)\n","negative_freq = nltk.FreqDist(negative_words)\n","print(\"Najčešće reči u pozitivnim tvitovima:\", positive_freq.most_common(5))\n","print(\"Najčešće reči u negativnim tvitovima:\", negative_freq.most_common(5))\n","\n","# Izračunavanje LR metrike\n","lr_metric = {word: positive_freq[word] / negative_freq[word] for word in set(positive_freq) & set(negative_freq) if positive_freq[word] >= 10 and negative_freq[word] >= 10}\n","sorted_lr = sorted(lr_metric.items(), key=lambda item: -item[1])\n","print(\"Top 5 reči sa najvećom LR vrednošću:\", sorted_lr[:5])\n","print(\"Top 5 reči sa najmanjom LR vrednošću:\", sorted_lr[-5:])\n"]},{"cell_type":"markdown","source":["Na osnovu datih ispisanih rijesenja dolazimo do iducih zakljucaka:\n","Model jako lose radi pri prisustvu linkova u tvitu, jer veliki broj tvitova u katastrofama zapravo koristi linkove na neke poznate novinarske sajtove nas porter stemmer prilikom ucitavanja linka ce ga samo skratiti na http, zato u oba slucaja pozitivnih i negativnih tvitoa rijec http je najcesca\n","Naprotiv logicnom razmisljanju dolazimo do iducih saznjanja vezanih za zapravo ostale rijeci koje se cesto pojavljuju:\n","Rijeci koje u svom obicnom bez-kontekstnom znacaju cesto imaju vezu za negativnim mislima ili losim stvarima poput fire, bomb, kill se zapravo cesto pojavjluju u pozitivnim tvitovima sto znaci da prosta analiza na osnovu samo rijec kao rijeci je nedovoljna vec da je kontekst jako bitan za bilo kakvo stvaranje predstave o znacaju tvita. Naizgled potpuno slican fenomen je primjetan u slucaju negativnih tvitova gdje se pojavljuju like, get, new, i stemovano \"amp\" sve rijeci za koje bi smo rekli da su pozitivne ali naizgled prkose ocekivanju.\n","Bitna napomena jeste da je nas klasifikator nakon 5 ponovljenih pokretanja dosao do neke srednje vrijednosti od ~75% tacnosti tako da cak iako je 3/4 jako dobro , greske su moguce.\n","Zatim vezano za LR vrijednosti tu zapravo vidimo kako visi LR pozitivno utice na izbor rijeci za klasifikovanje u pozitivne ili negativne tvitove a manja LR vrijednsot suprotno. Znajuci ovo u daljem radu sa analizom teksta bi bilo pametno uzimati LR u obzir kao neki vid konteksta odnosno koliko neke rijeci mogu kontekse recenice ili smisao da promjene na dobro ili na lose (vidno za ceste rijeci)\n","\n"],"metadata":{"id":"AsL4vWsBKVnS"}}]}